{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('train.json')\n",
    "train = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clusters': [[[17, 20], [23, 23]]], 'sentences': [['English', 'is', 'shown', 'to', 'be', 'trans-context-free', 'on', 'the', 'basis', 'of', 'coordinations', 'of', 'the', 'respectively', 'type', 'that', 'involve', 'strictly', 'syntactic', 'cross-serial', 'agreement', '.'], ['The', 'agreement', 'in', 'question', 'involves', 'number', 'in', 'nouns', 'and', 'reflexive', 'pronouns', 'and', 'is', 'syntactic', 'rather', 'than', 'semantic', 'in', 'nature', 'because', 'grammatical', 'number', 'in', 'English', ',', 'like', 'grammatical', 'gender', 'in', 'languages', 'such', 'as', 'French', ',', 'is', 'partly', 'arbitrary', '.'], ['The', 'formal', 'proof', ',', 'which', 'makes', 'crucial', 'use', 'of', 'the', 'Interchange', 'Lemma', 'of', 'Ogden', 'et', 'al.', ',', 'is', 'so', 'constructed', 'as', 'to', 'be', 'valid', 'even', 'if', 'English', 'is', 'presumed', 'to', 'contain', 'grammatical', 'sentences', 'in', 'which', 'respectively', 'operates', 'across', 'a', 'pair', 'of', 'coordinate', 'phrases', 'one', 'of', 'whose', 'members', 'has', 'fewer', 'conjuncts', 'than', 'the', 'other', ';', 'it', 'thus', 'goes', 'through', 'whatever', 'the', 'facts', 'may', 'be', 'regarding', 'constructions', 'with', 'unequal', 'numbers', 'of', 'conjuncts', 'in', 'the', 'scope', 'of', 'respectively', ',', 'whereas', 'other', 'arguments', 'have', 'foundered', 'on', 'this', 'problem', '.']], 'ner': [[[0, 0, 'Material'], [10, 10, 'OtherScientificTerm'], [17, 20, 'OtherScientificTerm']], [[23, 23, 'Generic'], [29, 29, 'OtherScientificTerm'], [31, 32, 'OtherScientificTerm'], [42, 43, 'OtherScientificTerm'], [45, 45, 'Material'], [48, 49, 'OtherScientificTerm'], [51, 51, 'Material'], [54, 54, 'Material']], [[70, 71, 'Method'], [86, 86, 'Material']]], 'relations': [[], [[29, 29, 31, 32, 'CONJUNCTION'], [48, 49, 51, 51, 'FEATURE-OF'], [54, 54, 51, 51, 'HYPONYM-OF']], []], 'doc_key': 'J87-1003', 'sentence_groups': [['English', 'is', 'shown', 'to', 'be', 'trans-context-free', 'on', 'the', 'basis', 'of', 'coordinations', 'of', 'the', 'respectively', 'type', 'that', 'involve', 'strictly', 'syntactic', 'cross-serial', 'agreement', '.', 'The', 'agreement', 'in', 'question', 'involves', 'number', 'in', 'nouns', 'and', 'reflexive', 'pronouns', 'and', 'is', 'syntactic', 'rather', 'than', 'semantic', 'in', 'nature', 'because', 'grammatical', 'number', 'in', 'English', ',', 'like', 'grammatical', 'gender', 'in', 'languages', 'such', 'as', 'French', ',', 'is', 'partly', 'arbitrary', '.'], ['English', 'is', 'shown', 'to', 'be', 'trans-context-free', 'on', 'the', 'basis', 'of', 'coordinations', 'of', 'the', 'respectively', 'type', 'that', 'involve', 'strictly', 'syntactic', 'cross-serial', 'agreement', '.', 'The', 'agreement', 'in', 'question', 'involves', 'number', 'in', 'nouns', 'and', 'reflexive', 'pronouns', 'and', 'is', 'syntactic', 'rather', 'than', 'semantic', 'in', 'nature', 'because', 'grammatical', 'number', 'in', 'English', ',', 'like', 'grammatical', 'gender', 'in', 'languages', 'such', 'as', 'French', ',', 'is', 'partly', 'arbitrary', '.', 'The', 'formal', 'proof', ',', 'which', 'makes', 'crucial', 'use', 'of', 'the', 'Interchange', 'Lemma', 'of', 'Ogden', 'et', 'al.', ',', 'is', 'so', 'constructed', 'as', 'to', 'be', 'valid', 'even', 'if', 'English', 'is', 'presumed', 'to', 'contain', 'grammatical', 'sentences', 'in', 'which', 'respectively', 'operates', 'across', 'a', 'pair', 'of', 'coordinate', 'phrases', 'one', 'of', 'whose', 'members', 'has', 'fewer', 'conjuncts', 'than', 'the', 'other', ';', 'it', 'thus', 'goes', 'through', 'whatever', 'the', 'facts', 'may', 'be', 'regarding', 'constructions', 'with', 'unequal', 'numbers', 'of', 'conjuncts', 'in', 'the', 'scope', 'of', 'respectively', ',', 'whereas', 'other', 'arguments', 'have', 'foundered', 'on', 'this', 'problem', '.'], ['The', 'agreement', 'in', 'question', 'involves', 'number', 'in', 'nouns', 'and', 'reflexive', 'pronouns', 'and', 'is', 'syntactic', 'rather', 'than', 'semantic', 'in', 'nature', 'because', 'grammatical', 'number', 'in', 'English', ',', 'like', 'grammatical', 'gender', 'in', 'languages', 'such', 'as', 'French', ',', 'is', 'partly', 'arbitrary', '.', 'The', 'formal', 'proof', ',', 'which', 'makes', 'crucial', 'use', 'of', 'the', 'Interchange', 'Lemma', 'of', 'Ogden', 'et', 'al.', ',', 'is', 'so', 'constructed', 'as', 'to', 'be', 'valid', 'even', 'if', 'English', 'is', 'presumed', 'to', 'contain', 'grammatical', 'sentences', 'in', 'which', 'respectively', 'operates', 'across', 'a', 'pair', 'of', 'coordinate', 'phrases', 'one', 'of', 'whose', 'members', 'has', 'fewer', 'conjuncts', 'than', 'the', 'other', ';', 'it', 'thus', 'goes', 'through', 'whatever', 'the', 'facts', 'may', 'be', 'regarding', 'constructions', 'with', 'unequal', 'numbers', 'of', 'conjuncts', 'in', 'the', 'scope', 'of', 'respectively', ',', 'whereas', 'other', 'arguments', 'have', 'foundered', 'on', 'this', 'problem', '.']], 'sentence_start_index': [0, 22, 38], 'sentence_end_index': [22, 60, 123]}\n"
     ]
    }
   ],
   "source": [
    "k=1\n",
    "for line in train:\n",
    "    js = json.loads(line)\n",
    "    n_sentences = len(js[\"sentences\"])\n",
    "    js[\"sentence_groups\"] = [[word for sentence in js[\"sentences\"][max(0, i-1):min(n_sentences, i + k + 1)] for word in sentence] for i in range(n_sentences)]\n",
    "    js[\"sentence_start_index\"] = [sum(len(js[\"sentences\"][i-j-1]) for j in range(min(k, i))) if i > 0 else 0 for i in range(n_sentences)]\n",
    "    js[\"sentence_end_index\"] = [js[\"sentence_start_index\"][i] + len(js[\"sentences\"][i]) for i in range(n_sentences)]\n",
    "    for sentence_group_nr in range(len(js[\"sentence_groups\"])):\n",
    "        if len(js[\"sentence_groups\"][sentence_group_nr]) > 300:\n",
    "            js[\"sentence_groups\"][sentence_group_nr] = js[\"sentences\"][sentence_group_nr]\n",
    "            js[\"sentence_start_index\"][sentence_group_nr] = 0\n",
    "            js[\"sentence_end_index\"][sentence_group_nr] = len(js[\"sentences\"][sentence_group_nr])\n",
    "    print(js)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(raw_tokens):\n",
    "    # token -> index\n",
    "    tokens = ['[CLS]']\n",
    "    idx_dict = dict()\n",
    "    cur_pos = 1\n",
    "\n",
    "    for i, token in enumerate(raw_tokens):\n",
    "        token = token.lower()\n",
    "        sub_words = tokenizer.tokenize(token)\n",
    "        tokens += sub_words\n",
    "        idx_dict[i] = list(range(cur_pos, cur_pos+len(sub_words)))\n",
    "        cur_pos += len(sub_words)\n",
    "\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    return indexed_tokens, idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokens, idx_dict = tokenize([\"This\", \"paper\", \"presents\", \"an\", \"algorithm\", \"for\", \"computing\", \"optical\", \"flow\", \",\", \"shape\", \",\", \"motion\", \",\", \"lighting\", \",\", \"and\", \"albedo\", \"from\", \"an\", \"image\", \"sequence\", \"of\", \"a\", \"rigidly-moving\", \"Lambertian\", \"object\", \"under\", \"distant\", \"illumination\", \".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'this',\n",
       " 'paper',\n",
       " 'presents',\n",
       " 'an',\n",
       " 'algorithm',\n",
       " 'for',\n",
       " 'computing',\n",
       " 'optical',\n",
       " 'flow',\n",
       " ',',\n",
       " 'shape',\n",
       " ',',\n",
       " 'motion',\n",
       " ',',\n",
       " 'lighting',\n",
       " ',',\n",
       " 'and',\n",
       " 'al',\n",
       " '##bedo',\n",
       " 'from',\n",
       " 'an',\n",
       " 'image',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'a',\n",
       " 'rigid',\n",
       " '##ly',\n",
       " '-',\n",
       " 'moving',\n",
       " 'lambert',\n",
       " '##ian',\n",
       " 'object',\n",
       " 'under',\n",
       " 'distant',\n",
       " 'illumination',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(indexed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
